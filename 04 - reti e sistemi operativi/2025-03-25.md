---
date: 2025-03-25
tags:
  - reti-e-sistemi-operativi
cssclasses:
---

## Tipi di parallelismo

Se un programma ha operazioni che agiscono su **dati indipendenti**, è possibile **parallelizzare** l'esecuzione assegnando a ciascun core un'operazione indipendente.

> [!example] Somma vettoriale
> Possiamo assegnare l'operazione di somma della componente $i$-esima al core $i$-esimo.

Un altro caso comune è quando i **dati sono condivisi**, ma vogliamo comunque parallelizzare.

> [!example] Calcolo simultaneo di MAX e MIN
> Supponiamo di avere un array da cui vogliamo calcolare il valore massimo (*MAX*) e minimo (*MIN*).
> Possiamo assegnare il calcolo di *MAX* a un core e il calcolo di *MIN* a un altro core.

## **User e Kernel Threads**

Se un programma ha più parti eseguibili in parallelo, possiamo utilizzare i **thread**.

### **User Threads**
I *User Threads* sono completamente invisibili al kernel, vivono nello **user space** e sono lo strumento che i programmatori utilizzano per implementare il parallelismo. Tuttavia, il kernel vede solo **un unico processo**.

### **Kernel Threads**
In Linux, sia i *Kernel Threads* che i processi sono chiamati **task**.
Se abbiamo 4 core, possiamo eseguire al massimo **4 Kernel Threads** contemporaneamente.

### **Relazione tra User e Kernel Thread**
Alcuni sistemi adottano il **mapping (N:1)**, sebbene sia poco comune:
- Il programma può utilizzare $N$ user thread, ma tutti vengono mappati su **un unico Kernel Thread**.
- In questo caso, l'esecuzione è limitata a un solo core.

> [!warning] Blocco del processo
> Se un *User Thread* effettua una richiesta di I/O (es. lettura da file), tutto il processo si ferma.

Un approccio più comune è il **mapping (1:1)**:
- Ogni *User Thread* è associato a un *Kernel Thread* separato, creato dal sistema operativo.
- Questo consente l'utilizzo di più core per l'esecuzione parallela.
## **Gestione dei Thread e Task in Java**

In Java, possiamo utilizzare una **thread pool**. Il programmatore deve solo definire la **task**, che verrà poi assegnata a un thread della pool.

- `newSingleThreadExecutor()` → Crea una pool con **un solo thread**.
- `newFixedThreadPool(int size)` → Crea una pool con un **numero fisso** di thread.
- `newCachedThreadPool()` → La dimensione della pool non è prefissata.

## **Fondamenti di Scheduling**

L'analisi empirica mostra che ogni processo alterna **fasi di calcolo** (CPU burst) e **operazioni di I/O**.

![[frequency-burst-cpu.png]]

Possiamo quindi classificare i processi come **CPU-bound** o **I/O-bound**.

## **Tre Tipi di Scheduler**
- **Lungo Termine** → Decide se un nuovo processo può entrare nel sistema.
- **Medio Termine** → Decide se un processo deve essere spostato tra **RAM** e **memoria di massa**.
- **Breve Termine** → Seleziona quale processo eseguire successivamente sulla CPU.

## **Scheduling: Preemptive vs Non-Preemptive**
Un processo può perdere la CPU in due modi:
- **Non-Preemptive** → Il processo rilascia la CPU solo in caso di **operazione di I/O** o **terminazione**.
- **Preemptive** → Il sistema può interrompere un processo per assegnare la CPU a un altro.

Il **scheduling preemptive** può causare **race conditions**, che devono essere gestite adeguatamente.

### **Quantum nel Preemptive Scheduling**
Il *quantum* è il **delta di tempo** per cui un processo può utilizzare la CPU prima di essere interrotto. Esiste un valore **ottimale** per evitare problemi di inefficienza.

## **Criteri di Scheduling**

| **Criterio** | **Descrizione** |
|-------------|----------------|
| *CPU Utilization* | Percentuale di tempo in cui la CPU è occupata. |
| *Throughput* | Numero di processi completati per unità di tempo. |
| *Turnaround Time* | Tempo totale impiegato da un processo per terminare. |
| *Waiting Time* | Tempo totale di attesa nella coda dei pronti. |
| *Response Time* | Tempo tra l'invio di una richiesta e la prima risposta. |

### **Obiettivi dello Scheduling**
- **Massimizzare** *CPU utilization*.
- **Massimizzare** *Throughput*.
- **Minimizzare** *Turnaround Time*.
- **Minimizzare** *Waiting Time*.
- **Minimizzare** *Response Time*.

> ⚠️ È possibile avere un'alta *CPU utilization* ma un basso *Throughput*, ad esempio nel **thrashing** dei sistemi multiprogrammati.

## **FCFS (First Come, First Served) Scheduling**
*(Sezione da completare...)*